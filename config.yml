use_gpu: true

# below params are what we now refer to as "OG" as in "original" from spring paper
#data:
#    sr: 16000
#    shift_ms: 10
#    fftl: 1024
#    num_mels: 80
#    hop_length: 160
#    top_db: 120
#    num_mfccs: 15

# below params are what we now refer to as "OG12" as in "original" from spring paper with 12 MFCC instead of 15
data:
    sr: 16000
    shift_ms: 10
    fftl: 1024
    num_mels: 80
    hop_length: 160
    top_db: 120
    num_mfccs: 12

# below params are what we have been using for everything up until the final week
#data:
#    sr: 40000
#    shift_ms: 10
#    fftl: 2048
#    num_mels: 160
#    hop_length: 400
#    top_db: 120
#    num_mfccs: 15

directories:
    exps: exps/
    dicova_root: DiCOVA/
    dicova_test_root: DiCOVA_Test/

model:
    name: dummy

pretraining2:
    lr: 0.0001
    # future frames was 10 but then I remembered we have sr of 40000 instead of 16000
    # keep it at 10!!!!!!
    future_frames: 10
    hidden_size: 400
    linear_hidden_size: 500
    encoder1_num_layers: 2
    encoder2_num_layers: 2
    batch_first: true
    dropout: 0.1
    log_step: 100
    model_save_step: 5000
    num_epochs: 1000
    batch_size: 3
    specaug_probability: 0.0
    upscale: 30

post_pretraining_classifier:
    lr: 0.0001
    hidden_size: 200
    linear_hidden_size: 300
    encoder_num_layers: 2
    batch_first: true
    dropout: 0.1
    opensmile_dropout: 0.1
    bidirectional: true
    incorrect_scaler: 1
    log_step: 100
    model_save_step: 500
    num_epochs: 1000
    batch_size: 3
    specaug_probability: 1.0
    pooled_size: 32

classifier:
    lr: 0.0001
    hidden_size: 200
    linear_hidden_size: 300
    encoder_num_layers: 2
    batch_first: true
    dropout: 0.1
    opensmile_dropout: 0.1
    bidirectional: true
    incorrect_scaler: 1
    log_step: 100
    model_save_step: 500
    num_epochs: 1000
    batch_size: 3
    specaug_probability: 1.0

